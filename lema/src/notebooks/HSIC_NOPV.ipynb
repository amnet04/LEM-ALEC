{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CÃ¡lculos de HSIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "/opt/conda/lib/python3.5/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# Add the ptdraft folder path to the sys.path list\n",
    "sys.path.append('/src')\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import pandas\n",
    "import re\n",
    "from HSIC.HSIC import HSIC_no_pval\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORDS_ORIGIN = \"/src/data/procesados/clean/TWITTER_COLOMBIA_FREQ_CLEAN.csv\"\n",
    "CITIES_ORIGIN = \"/src/data/procesados/geo/filter_cities_coordinates.csv\"\n",
    "DESTINO = \"/src/data/procesados/HSIC/HSIC_RANK_NORM_SIN_PVALUE_FREQ.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def escribir_cabezote_archivo(destino, fieldnames):\n",
    "    with open(destino, 'w') as csvfile:\n",
    "        writer = fieldnames.to_csv(csvfile,sep=\"\\t\",header=fieldnames.columns,decimal=\",\")\n",
    "        \n",
    "def escribir_datos_archivo(destino, values):\n",
    "    with open(destino, 'a') as csvfile:\n",
    "        writer = values.to_csv(csvfile,sep=\"\\t\",header=False,decimal=\",\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hsic_no_pvalue_to_file(words_file, cities_file, destino):\n",
    "    words = pandas.read_csv(\n",
    "        words_file, \n",
    "        encoding='utf-8',\n",
    "        chunksize=1,\n",
    "        index_col=0,\n",
    "        skiprows=[1],\n",
    "        sep =\"\\t\",\n",
    "        decimal=\",\",\n",
    "        quotechar='\"'\n",
    "    )\n",
    "    cities = pandas.read_csv(\n",
    "        cities_file, \n",
    "        encoding='utf-8',\n",
    "        sep =\"\\t\",\n",
    "        decimal=\",\",\n",
    "        quotechar='\"',\n",
    "        usecols=['ciudad', 'Latitud','Longitud'],\n",
    "        index_col =0\n",
    "    ).transpose()\n",
    "\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for chunk  in words:\n",
    "        start_time = time.time()\n",
    "        data = pandas.concat([cities,chunk]).transpose()\n",
    "        word_vector = data.iloc[0:, 2:3].as_matrix()\n",
    "        #Linealizar\n",
    "        linear_word_vector = np.log(word_vector+1)\n",
    "        cities_vector = data.iloc[0:, 0:2].as_matrix()\n",
    "        hsic=HSIC_no_pval(cities_vector,word_vector, kernelX=\"Gaussian\", kernelY=\"Gaussian\")\n",
    "        hsic_lin=HSIC_no_pval(cities_vector,linear_word_vector, kernelX=\"Gaussian\", kernelY=\"Gaussian\")\n",
    "        basic_header = pandas.DataFrame({\n",
    "            'HSIC':pandas.Series([], dtype='float'),\n",
    "            'HSIC_LIN':pandas.Series([], dtype='float')\n",
    "        })\n",
    "        basic_header.loc['{}'.format(chunk.index[0]),'HSIC']=hsic\n",
    "        basic_header.loc['{}'.format(chunk.index[0]),'HSIC_LIN']=hsic_lin\n",
    "        if count == 0:\n",
    "            escribir_cabezote_archivo(destino, basic_header)\n",
    "        else:\n",
    "            escribir_datos_archivo(destino, basic_header)\n",
    "        count = count + 1\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print ('\\rDuracion:{}\\t procesados:{}\\t palabra:{}\\t'.format(elapsed_time,count, chunk.index.values[0]),end='\\t')\n",
    "    \n",
    "    return(hsic, hsic_lin)\n",
    "            \n",
    "    \n",
    "    \"\"\"print('\\n \\n Frito el pollo')\"\"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con frecuencias absolutas \n",
    "\n",
    "WORDS_ORIGIN = \"/src/data/procesados/clean/TWITTER_COLOMBIA_FREQ_CLEAN.csv\"\n",
    "CITIES_ORIGIN = \"/src/data/procesados/geo/filter_cities_coordinates.csv\"\n",
    "DESTINO = \"/src/data/procesados/HSIC/HSIC_SIN_PVALUE_FREQ.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duracion:0.06232762336730957\t procesados:130464\t palabra:casaenelagua\t\t\t\t\t\t\t\tbas\t\tlicaigual\t\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duracion:0.057520389556884766\t procesados:413040\t palabra:tardata\t\t\t\tntoss\t\t\t\ty\t\tte\t\t\tiaz\t\ttiaportiypensarasenmiaunqueesteslejos\t\tu\t\t\t\thablandohermosofiebreanochededicarimagenes\t\tatarara\t\t"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7.1257991320446221e-05, 7.1257991320446221e-05)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hsic_no_pvalue_to_file(WORDS_ORIGIN, CITIES_ORIGIN, DESTINO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con frecuencias realtivas \n",
    "\n",
    "WORDS_ORIGIN = \"/src/data/procesados/clean/TWITTER_COLOMBIA_RELATIVE_FREQ_CLEAN.csv\"\n",
    "DESTINO = \"/src/data/procesados/HSIC/HSIC_SIN_PVALUE_REL_FREQ.csv\"\n",
    "def hsic_no_pvalue_to_file(words_file, cities_file, destino):\n",
    "    words = pandas.read_csv(\n",
    "        words_file, \n",
    "        encoding='utf-8',\n",
    "        chunksize=1,\n",
    "        index_col=0,\n",
    "        skiprows=[1],\n",
    "        sep =\"\\t\",\n",
    "        decimal=\",\",\n",
    "        quotechar='\"'\n",
    "    )\n",
    "    cities = pandas.read_csv(\n",
    "        cities_file, \n",
    "        encoding='utf-8',\n",
    "        sep =\"\\t\",\n",
    "        decimal=\",\",\n",
    "        quotechar='\"',\n",
    "        usecols=['ciudad', 'Latitud','Longitud'],\n",
    "        index_col =0\n",
    "    ).transpose()\n",
    "\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for chunk  in words:\n",
    "        start_time = time.time()\n",
    "        data = pandas.concat([cities,chunk]).transpose()\n",
    "        word_vector = data.iloc[0:, 2:3].as_matrix()\n",
    "        #Linealizar\n",
    "        linear_word_vector = np.log(word_vector*100000000+1)\n",
    "        cities_vector = data.iloc[0:, 0:2].as_matrix()\n",
    "        hsic=HSIC_no_pval(cities_vector,word_vector, kernelX=\"Gaussian\", kernelY=\"Gaussian\")\n",
    "        hsic_lin=HSIC_no_pval(cities_vector,linear_word_vector, kernelX=\"Gaussian\", kernelY=\"Gaussian\")\n",
    "        basic_header = pandas.DataFrame({\n",
    "            'HSIC':pandas.Series([], dtype='float'),\n",
    "            'HSIC_LIN':pandas.Series([], dtype='float')\n",
    "        })\n",
    "        basic_header.loc['{}'.format(chunk.index[0]),'HSIC']=hsic\n",
    "        basic_header.loc['{}'.format(chunk.index[0]),'HSIC_LIN']=hsic_lin\n",
    "        if count == 0:\n",
    "            escribir_cabezote_archivo(destino, basic_header)\n",
    "        else:\n",
    "            escribir_datos_archivo(destino, basic_header)\n",
    "        count = count + 1\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print ('\\rDuracion:{}\\t procesados:{}\\t palabra:{}\\t'.format(elapsed_time,count, chunk.index.values[0]),end='\\t')\n",
    "    \n",
    "    return(hsic, hsic_lin)\n",
    "            \n",
    "    \n",
    "    \"\"\"print('\\n \\n Frito el pollo')\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duracion:0.06262326240539551\t procesados:130464\t palabra:casaenelagua\t\t\t\t\t\t\t\tabas\t\ticaigual\t\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duracion:0.05773282051086426\t procesados:413040\t palabra:tardata\t\tr\t\tntoss\t\thy\t\tnte\t\t\t\taz\t\tiaportiypensarasenmiaunqueesteslejos\t\tstu\t\t\trhablandohermosofiebreanochededicarimagenes\t\ttarara\t\t"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.0840356939155631e-05, 5.6746378647835256e-05)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hsic_no_pvalue_to_file(WORDS_ORIGIN, CITIES_ORIGIN, DESTINO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con ranks \n",
    "\n",
    "WORDS_ORIGIN = \"/src/data/procesados/clean/TWITTER_COLOMBIA_RANK.csv\"\n",
    "DESTINO = \"/src/data/procesados/HSIC/HSIC_SIN_PVALUE_RANK.csv\"\n",
    "\n",
    "def hsic_no_pvalue_to_file(words_file, cities_file, destino):\n",
    "    words = pandas.read_csv(\n",
    "        words_file, \n",
    "        encoding='utf-8',\n",
    "        chunksize=1,\n",
    "        index_col=0,\n",
    "        skiprows=[1],\n",
    "        sep =\"\\t\",\n",
    "        decimal=\",\",\n",
    "        quotechar='\"'\n",
    "    )\n",
    "    cities = pandas.read_csv(\n",
    "        cities_file, \n",
    "        encoding='utf-8',\n",
    "        sep =\"\\t\",\n",
    "        decimal=\",\",\n",
    "        quotechar='\"',\n",
    "        usecols=['ciudad', 'Latitud','Longitud'],\n",
    "        index_col =0\n",
    "    ).transpose()\n",
    "\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for chunk  in words:\n",
    "        start_time = time.time()\n",
    "        data = pandas.concat([cities,chunk]).transpose()\n",
    "        word_vector = data.iloc[0:, 2:3].as_matrix()\n",
    "        #Linealizar\n",
    "        linear_word_vector = np.log(word_vector)\n",
    "        cities_vector = data.iloc[0:, 0:2].as_matrix()\n",
    "        hsic=HSIC_no_pval(cities_vector,word_vector, kernelX=\"Gaussian\", kernelY=\"Gaussian\")\n",
    "        hsic_lin=HSIC_no_pval(cities_vector,linear_word_vector, kernelX=\"Gaussian\", kernelY=\"Gaussian\")\n",
    "        basic_header = pandas.DataFrame({\n",
    "            'HSIC':pandas.Series([], dtype='float'),\n",
    "            'HSIC_LIN':pandas.Series([], dtype='float')\n",
    "        })\n",
    "        basic_header.loc['{}'.format(chunk.index[0]),'HSIC']=hsic\n",
    "        basic_header.loc['{}'.format(chunk.index[0]),'HSIC_LIN']=hsic_lin\n",
    "        if count == 0:\n",
    "            escribir_cabezote_archivo(destino, basic_header)\n",
    "        else:\n",
    "            escribir_datos_archivo(destino, basic_header)\n",
    "        count = count + 1\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print ('\\rDuracion:{}\\t procesados:{}\\t palabra:{}\\t'.format(elapsed_time,count, chunk.index.values[0]),end='\\t')\n",
    "    \n",
    "    return(hsic, hsic_lin)\n",
    "            \n",
    "    \n",
    "    \"\"\"print('\\n \\n Frito el pollo')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duracion:0.08089518547058105\t procesados:413040\t palabra:tardata\t\tr\t\tntoss\t\t\ty\t\tte\t\t\t\t\tz\t\ttiaportiypensarasenmiaunqueesteslejos\t\tu\t\ta\t\thablandohermosofiebreanochededicarimagenes\t\tatarara\t\t\t\t\t\t\t\t"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0022058080345603972, 0.0025490468509971418)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hsic_no_pvalue_to_file(WORDS_ORIGIN, CITIES_ORIGIN, DESTINO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con ranks normalizados\n",
    "\n",
    "# Corregir #\n",
    "\n",
    "WORDS_ORIGIN = \"/src/data/procesados/clean/TWITTER_COLOMBIA_RANK_NORM.csv\"\n",
    "DESTINO = \"/src/data/procesados/HSIC/HSIC_SIN_PVALUE_RANK_NORM.csv\"\n",
    "\n",
    "def hsic_no_pvalue_to_file(words_file, cities_file, destino):\n",
    "    words = pandas.read_csv(\n",
    "        words_file, \n",
    "        encoding='utf-8',\n",
    "        chunksize=1,\n",
    "        index_col=0,\n",
    "        skiprows=[1],\n",
    "        sep =\"\\t\",\n",
    "        decimal=\",\",\n",
    "        quotechar='\"'\n",
    "    )\n",
    "    cities = pandas.read_csv(\n",
    "        cities_file, \n",
    "        encoding='utf-8',\n",
    "        sep =\"\\t\",\n",
    "        decimal=\",\",\n",
    "        quotechar='\"',\n",
    "        usecols=['ciudad', 'Latitud','Longitud'],\n",
    "        index_col =0\n",
    "    ).transpose()\n",
    "\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for chunk  in words:\n",
    "        start_time = time.time()\n",
    "        data = pandas.concat([cities,chunk]).transpose()\n",
    "        word_vector = data.iloc[0:, 2:3].as_matrix()\n",
    "        #Linealizar\n",
    "        linear_word_vector = np.log(word_vector*100000000)\n",
    "        cities_vector = data.iloc[0:, 0:2].as_matrix()\n",
    "        hsic=HSIC_no_pval(cities_vector,word_vector, kernelX=\"Gaussian\", kernelY=\"Gaussian\")\n",
    "        hsic_lin=HSIC_no_pval(cities_vector,linear_word_vector, kernelX=\"Gaussian\", kernelY=\"Gaussian\")\n",
    "        basic_header = pandas.DataFrame({\n",
    "            'HSIC':pandas.Series([], dtype='float'),\n",
    "            'HSIC_LIN':pandas.Series([], dtype='float')\n",
    "        })\n",
    "        basic_header.loc['{}'.format(chunk.index[0]),'HSIC']=hsic\n",
    "        basic_header.loc['{}'.format(chunk.index[0]),'HSIC_LIN']=hsic_lin\n",
    "        if count == 0:\n",
    "            escribir_cabezote_archivo(destino, basic_header)\n",
    "        else:\n",
    "            escribir_datos_archivo(destino, basic_header)\n",
    "        count = count + 1\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print ('\\rDuracion:{}\\t procesados:{}\\t palabra:{}\\t'.format(elapsed_time,count, chunk.index.values[0]),end='\\t')\n",
    "    \n",
    "    return(hsic, hsic_lin)\n",
    "            \n",
    "    \n",
    "    \"\"\"print('\\n \\n Frito el pollo')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duracion:0.06386399269104004\t procesados:130465\t palabra:chancesito\t\t\t\t\t\t\t\t\t\tbas\t\tplicaigual\t\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duracion:0.06587386131286621\t procesados:413040\t palabra:tardata\t\t\t\tentoss\t\t\t\t\tnte\t\t\ta\t\taz\t\taportiypensarasenmiaunqueesteslejos\t\ttu\t\t\t\thablandohermosofiebreanochededicarimagenes\t\tatarara\t\t\t"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.3516649115002447e-05, 3.3498135597693545e-05)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hsic_no_pvalue_to_file(WORDS_ORIGIN, CITIES_ORIGIN, DESTINO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
