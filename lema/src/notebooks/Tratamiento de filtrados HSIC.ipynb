{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T08:05:02.004950Z",
     "start_time": "2018-02-05T08:05:01.021307Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import wilcoxon, ranksums\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T08:33:32.790273Z",
     "start_time": "2018-02-05T08:33:32.785096Z"
    }
   },
   "outputs": [],
   "source": [
    "TOT_FREQ_ORIGIN = \"/src/data/procesados/clean/TWITTER_COLOMBIA_FREQ_CLEAN.csv\"\n",
    "REL_FREQ_ORIGIN = \"/src/data/procesados/clean/TWITTER_COLOMBIA_RELATIVE_FREQ_CLEAN.csv\"\n",
    "CITIES_ORIGIN = \"/src/data/procesados/geo/filter_cities_coordinates.csv\"\n",
    "HSIC_ORIGIN = \"/src/data/procesados/HSIC/HSIC_PVALUE.csv\"\n",
    "DESTINO = \"/src/data/procesados/filtered/Filter20MILData.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T08:33:33.097831Z",
     "start_time": "2018-02-05T08:33:33.088941Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "def colombia_norm_freq(freq_file):\n",
    "    tot_freqs = pd.read_csv(\n",
    "        freq_file, \n",
    "        encoding='utf-8',\n",
    "        index_col=0,\n",
    "        sep =\"\\t\",\n",
    "        decimal=\",\",\n",
    "        quotechar='\"'\n",
    "    ).transpose()\n",
    "    \n",
    "    total = pd.DataFrame(tot_freqs.apply(np.sum), columns=[\"#TOTALES_COLOMBIA#\"])\n",
    "    del tot_freqs\n",
    "    total_norm = (total.iloc[0:]/total.iloc[0]).drop(\"#TOTAL_WORDS#\")\n",
    "    return(total_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T08:34:01.188949Z",
     "start_time": "2018-02-05T08:33:33.620213Z"
    }
   },
   "outputs": [],
   "source": [
    "colombia = colombia_norm_freq(TOT_FREQ_ORIGIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T08:34:01.197449Z",
     "start_time": "2018-02-05T08:34:01.190777Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def hsic_filter(hsic_filter_file):\n",
    "    hsics = pd.read_csv(\n",
    "        hsic_filter_file, \n",
    "        encoding='utf-8',\n",
    "        index_col=0,\n",
    "        sep =\"\\t\",\n",
    "        decimal=\",\",\n",
    "        quotechar='\"'\n",
    "    )\n",
    "    print(len(hsics))\n",
    "    hsics=hsics[hsics.PValue<0.05]\n",
    "    print(len(hsics))\n",
    "    hsic_fil = hsics.index\n",
    "    return(hsic_fil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T08:34:01.241470Z",
     "start_time": "2018-02-05T08:34:01.199598Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "15938\n"
     ]
    }
   ],
   "source": [
    " #hsic_fil=hsic_filter(HSIC_ORIGIN )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T04:52:39.647645Z",
     "start_time": "2018-01-29T04:52:39.630809Z"
    },
    "code_folding": [],
    "deletable": false,
    "editable": false,
    "hide_input": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def filter_words_frame_file(hsic_fil, totals ,rel_freq_file, destino):\n",
    "    words_data = pd.read_csv(\n",
    "        rel_freq_file, \n",
    "        encoding='utf-8',\n",
    "        index_col=0,\n",
    "        sep =\"\\t\",\n",
    "        decimal=\",\",\n",
    "        quotechar='\"'\n",
    "    )\n",
    "    \n",
    "    words_to_drop = list(set(list(words_data.index))-set(hsic_fil))\n",
    "    words_data.drop(labels=words_to_drop, inplace=True)\n",
    "    words_to_drop = list(set(list(totals.index))-set(hsic_fil))\n",
    "    totals.drop(labels=words_to_drop, inplace=True)\n",
    "    \n",
    "    frame = [totals, words_data]\n",
    "    words_data = pd.concat(frame, axis=1)\n",
    "    \n",
    "    words_data.to_csv(destino, sep=\"\\t\",decimal=\",\",header=words_data.columns)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T07:59:25.192123Z",
     "start_time": "2018-02-05T07:59:25.187983Z"
    },
    "code_folding": [],
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "#filter_words_frame_file(hsic_fil, colombia, REL_FREQ_ORIGIN, DESTINO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_statistis(origin, pueblo1, pueblo2):\n",
    "    words_data = pd.read_csv(\n",
    "        origin, \n",
    "        encoding='utf-8',\n",
    "        index_col=0,\n",
    "        sep =\"\\t\",\n",
    "        decimal=\",\",\n",
    "        quotechar='\"'\n",
    "    )\n",
    "    pueblo1_frame=pd.DataFrame(words_data[pueblo1])\n",
    "    pueblo2_frame=pd.DataFrame(words_data[pueblo2])\n",
    "    pueblo1_frame=pueblo1_frame[getattr(pueblo1_frame,pueblo1) != 0]\n",
    "    pueblo2_frame=pueblo2_frame[getattr(pueblo2_frame,pueblo2) != 0]\n",
    "    pueblo1_len = len(pueblo1_frame)\n",
    "    pueblo2_len = len(pueblo2_frame)\n",
    "    pueblo1_mean = pueblo1_frame.stack().mean()\n",
    "    pueblo2_mean = pueblo2_frame.stack().mean()\n",
    "    pueblo1_median = pueblo1_frame.stack().median()\n",
    "    pueblo2_median = pueblo2_frame.stack().median()\n",
    "    return(pueblo1_len, pueblo2_len, pueblo1_mean, pueblo2_mean, pueblo1_median, pueblo2_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15878,\n",
       " 15915,\n",
       " 4.8062218751686614e-05,\n",
       " 4.8013203563900886e-05,\n",
       " 2.6491270005748604e-06,\n",
       " 2.6468636822069587e-06)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_statistis(DESTINO, \"Medellín\", \"Bogotá\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T05:44:44.307388Z",
     "start_time": "2018-01-29T05:44:44.259842Z"
    },
    "code_folding": [],
    "hide_input": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def wilcoxon_signedrank_matrix_all_corpus(origin, method=\"wilcox\", normalize=False, zeros=False):\n",
    "    destination_folder=\"/src/data/procesados/wilcoxon_signed/allcorpus/{}/\".format(method)\n",
    "    words_data = pd.read_csv(\n",
    "        origin, \n",
    "        encoding='utf-8',\n",
    "        index_col=0,\n",
    "        sep =\"\\t\",\n",
    "        decimal=\",\",\n",
    "        quotechar='\"'\n",
    "    )\n",
    "    \n",
    "    wilcoxon_dataframe = pd.DataFrame(columns=words_data.columns, dtype=np.int32)\n",
    "    pvalue_dataframe = pd.DataFrame(columns=words_data.columns, dtype=np.float64)\n",
    "    norm_wilcoxon_dataframe = pd.DataFrame(columns=words_data.columns, dtype=np.float64)\n",
    "    dist_dataframe = pd.DataFrame(columns=words_data.columns, dtype=np.float64)\n",
    "    \n",
    "    if normalize==True:\n",
    "        destination_folder=\"/src/data/procesados/wilcoxon_signed/normalized_allcorpus/{}/\".format(method)\n",
    "        # renormalizar\n",
    "        totales = pd.DataFrame(words_data.apply(np.sum), columns=[\"#TOTALES#\"]).transpose()\n",
    "        words_data = pd.concat([totales, words_data])\n",
    "        words_data = words_data.iloc[0:]/words_data.iloc[0]\n",
    "        words_data.drop(labels=[\"#TOTALES#\"], inplace=True)\n",
    "        \n",
    "    if zeros:\n",
    "        destination_folder=\"{}/{}/{}\".format(destination_folder,zeros,method)\n",
    "                   \n",
    "    for column1 in words_data:\n",
    "        for column2 in words_data:\n",
    "            diferencia = pd.DataFrame(words_data[column1]-words_data[column2], columns=[\"diferencia\"])\n",
    "            diferencia_prom = np.float64(abs(diferencia.sum())/len(diferencia))\n",
    "            if zeros:\n",
    "                pueblo1_len, pueblo2_len, pueblo1_mean, pueblo2_mean, pueblo1_median, pueblo2_median=corpus_statistis(origin, column1, column2)\n",
    "                if zeros==\"maxmedian\":      \n",
    "                    if pueblo1_len > pueblo2_len:\n",
    "                        words_data[column2]=words_data[column2].replace(0,pueblo1_median)\n",
    "                    if pueblo1_len < pueblo2_len:\n",
    "                        words_data[column1]=words_data[column1].replace(0,pueblo2_median)        \n",
    "                if zeros==\"conjmedian\":\n",
    "                    words_data[column2]=words_data[column2].replace(0,pueblo1_median)\n",
    "                    words_data[column1]=words_data[column1].replace(0,pueblo2_median)\n",
    "            if method == \"wilcox\":\n",
    "                ceros = len(diferencia[diferencia.diferencia == 0])\n",
    "                n = len(diferencia)-ceros\n",
    "            elif method == \"pratt\" or method == \"zsplit\":\n",
    "                n = len(words_data[column2])\n",
    "            # s = n*(n+1)/2 este no hay que buscar porque funciona con 4\n",
    "            s = n*(n+1)/4\n",
    "            wil, pvalue = wilcoxon(words_data[column1],words_data[column2],zero_method=method)\n",
    "            nwil = wil/s\n",
    "            print('\\r{}:{} w:{} p:{}'.format(column1,column2,wil,pvalue), end=\"\\t\\t\")\n",
    "            pvalue_dataframe.loc[column1, column2]=pvalue\n",
    "            dist_dataframe.loc[column1, column2]=diferencia_prom\n",
    "            if pvalue < 0.05:\n",
    "                wilcoxon_dataframe.loc[column1, column2]=wil\n",
    "                norm_wilcoxon_dataframe.loc[column1, column2]=nwil\n",
    "            else:\n",
    "                wilcoxon_dataframe.loc[column1, column2]=np.nan\n",
    "                norm_wilcoxon_dataframe.loc[column1, column2]=np.nan\n",
    "        print('\\nTerminado {}'.format(column1), end=\"\\n\")\n",
    " \n",
    "    wilcoxon_dataframe.to_csv('{}{}'.format(destination_folder,'stat.csv'),sep=\"\\t\",decimal=\",\",header=wilcoxon_dataframe.columns)\n",
    "    pvalue_dataframe.to_csv('{}{}'.format(destination_folder,'pvalue.csv'),sep=\"\\t\",decimal=\",\",header=pvalue_dataframe.columns)\n",
    "    norm_wilcoxon_dataframe.to_csv('{}{}'.format(destination_folder,'nstat.csv'),sep=\"\\t\",decimal=\",\",header=norm_wilcoxon_dataframe.columns)\n",
    "    dist_dataframe.to_csv('{}{}'.format(destination_folder,'distancia.csv'),sep=\"\\t\",decimal=\",\",header=dist_dataframe.columns)\n",
    "    print('\\nTerminado {}/{}'.format(method,zero), end=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T05:48:37.938866Z",
     "start_time": "2018-01-29T05:44:47.270340Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#TOTALES_COLOMBIA#:Zipaquirá w:61600678.0 p:0.0010191849672664555\t\t\t\t8e-181\t\t46\t\t\n",
      "Terminado #TOTALES_COLOMBIA#\n",
      "Acevedo:Zipaquirá w:40123049.0 p:0.0\t\t0926138456e-170\t\t71025e-87\t\t61\t\t\n",
      "Terminado Acevedo\n",
      "Aguachica:Zipaquirá w:45072566.0 p:4.096179230923277e-221\t\t206\t\t165\t\t9\t\t\t\n",
      "Terminado Aguachica\n",
      "Agustín Codazi:Zipaquirá w:47464111.0 p:5.266750664635652e-168\t\t144\t\t29\t\t36\t\t\n",
      "Terminado Agustín Codazi\n",
      "Albania:Zipaquirá w:45129316.0 p:8.642386931255364e-220\t\t98\t\t-78\t\t14\t\t\n",
      "Terminado Albania\n",
      "Andes:Zipaquirá w:47989502.0 p:2.584245278994446e-157\t\t31\t\t-201\t\t82\t\t\n",
      "Terminado Andes\n",
      "Apartadó:Zipaquirá w:44394016.0 p:1.587545257241938e-237\t\t41\t\t-129\t\t\t\t\t\t\n",
      "Terminado Apartadó\n",
      "Arauca:Zipaquirá w:43311338.0 p:6.03853928770277e-265\t\t256\t\t36\t\t-38\t\t\n",
      "Terminado Arauca\n",
      "Armenia:Zipaquirá w:52587396.0 p:7.264204786586766e-79\t\t-62\t\t268\t\t\t\t\n",
      "Terminado Armenia\n",
      "Baranoa:Zipaquirá w:63348554.0 p:0.7824514010289454\t\t\t\t\t\t\t05e-224\t\t3\t\t\t\n",
      "Terminado Baranoa\n",
      "Barbosa_Antioquia:Zipaquirá w:51990706.0 p:1.6478466452647962e-87\t\t67\t\t-59\t\t15\t\t\n",
      "Terminado Barbosa_Antioquia\n",
      "Barbosa_Santander:Zipaquirá w:40515974.0 p:0.0\t\t7898622153e-196\t\t8785e-117\t\t\t\t\t\t\t\n",
      "Terminado Barbosa_Santander\n",
      "Barrancabermeja:Zipaquirá w:59871195.0 p:3.7857063586517705e-10\t\t06\t\t-200\t\t\t\t\n",
      "Terminado Barrancabermeja\n",
      "Barranquilla:Zipaquirá w:55365650.0 p:1.191301937590142e-44\t\t65\t\te-266\t\t7\t\t\n",
      "Terminado Barranquilla\n",
      "Belen de Umbría:Zipaquirá w:42192725.0 p:6.649734977956811e-295\t\t245\t\t69\t\t102\t\t\n",
      "Terminado Belen de Umbría\n",
      "Bogotá:Zipaquirá w:57430034.0 p:1.2488133933040102e-25\t\t0\t\t-169\t\t58\t\t\n",
      "Terminado Bogotá\n",
      "Bolivar:Zipaquirá w:45882535.0 p:2.794419822066812e-202\t\t169\t\t5\t\t231\t\t\n",
      "Terminado Bolivar\n",
      "Bosconia:Zipaquirá w:46414840.0 p:2.0390506674432186e-190\t\t58\t\t90\t\t263\t\t\n",
      "Terminado Bosconia\n",
      "Bucaramanga:Zipaquirá w:60036891.0 p:2.2683088189620514e-09\t\t1\t\te-201\t\t9\t\t\n",
      "Terminado Bucaramanga\n",
      "Buenaventura:Zipaquirá w:60008856.0 p:1.6844736606187644e-09\t\t13\t\t-117\t\t\t\t\t\t\n",
      "Terminado Buenaventura\n",
      "Buga:Zipaquirá w:54218835.0 p:1.413108187616327e-57\t\t66\t\te-62\t\t18\t\t\t\n",
      "Terminado Buga\n",
      "Cali:Zipaquirá w:61900056.0 p:0.0056093350579151545\t\t82\t\te-153\t\t5\t\t\n",
      "Terminado Cali\n",
      "Campo de la Cruz:Zipaquirá w:45431399.0 p:1.0773250470494475e-212\t\t74\t\t126\t\t\t\t\t\n",
      "Terminado Campo de la Cruz\n",
      "Cáqueza:Zipaquirá w:40004482.0 p:0.0\t\t6732287086e-148\t\te-297\t\t53\t\t6\t\t\t\t\n",
      "Terminado Cáqueza\n",
      "Carepa:Zipaquirá w:51506172.0 p:6.7648897404284e-95\t\te-81\t\t\t\t-57\t\t\n",
      "Terminado Carepa\n",
      "Cartagena:Zipaquirá w:60487096.0 p:1.968672037991788e-07\t\t-25\t\t231\t\t4\t\t\t\t\n",
      "Terminado Cartagena\n",
      "Caucasia:Zipaquirá w:42444044.0 p:5.277600834942085e-288\t\t90\t\t137\t\t7\t\t\t\t\n",
      "Terminado Caucasia\n",
      "Cereté:Zipaquirá w:53146274.0 p:3.432355592023988e-71\t\t70\t\te-115\t\t2\t\t\n",
      "Terminado Cereté\n",
      "Chaparral:Zipaquirá w:48649718.0 p:2.1706615842135488e-144\t\t5\t\t-289\t\t\t\n",
      "Terminado Chaparral\n",
      "Chigorodó:Zipaquirá w:50019805.0 p:2.42396495348254e-119\t\t98\t\t\t-54\t\t\t\n",
      "Terminado Chigorodó\n",
      "Chimichagua:Zipaquirá w:49089701.0 p:4.430240826256364e-136\t\t7\t\t\t\t-78\t\t\n",
      "Terminado Chimichagua\n",
      "Chinú:Zipaquirá w:43307087.0 p:4.5340787672183917e-265\t\t2\t\t-125\t\t9\t\t\t\n",
      "Terminado Chinú\n",
      "Chiriguaná:Zipaquirá w:53060333.0 p:2.2643799892799214e-72\t\t2\t\t\t9e-80\t\t\n",
      "Terminado Chiriguaná\n",
      "Ciénaga de Oro:Zipaquirá w:57249558.0 p:4.465904857754736e-27\t\t-30\t\t-146\t\t6\t\t\t\n",
      "Terminado Ciénaga de Oro\n",
      "Ciénaga:Zipaquirá w:49370295.0 p:7.0933529973289e-131\t\te-108\t\t4\t\t-206\t\t\n",
      "Terminado Ciénaga\n",
      "Concordia:Zipaquirá w:48623013.0 p:7.41521995553185e-145\t\t116\t\t57\t\t-231\t\t\n",
      "Terminado Concordia\n",
      "Corinto:Zipaquirá w:42912229.0 p:2.037434501976301e-275\t\t8\t\t-18\t\t-142\t\t\n",
      "Terminado Corinto\n",
      "Coyaima:Zipaquirá w:42260391.0 p:4.728606418564405e-293\t\t93\t\t72\t\t140\t\t\n",
      "Terminado Coyaima\n",
      "Cúcuta:Zipaquirá w:57450837.0 p:1.8213740828286285e-25\t\t2\t\te-201\t\t\t\t\n",
      "Terminado Cúcuta\n",
      "Cumaral:Zipaquirá w:45815710.0 p:7.725965018822996e-204\t\t13\t\t93\t\t162\t\t\t\n",
      "Terminado Cumaral\n",
      "Curumaní:Zipaquirá w:49512852.0 p:2.509198241032934e-128\t\t106\t\t-309\t\t\n",
      "Terminado Curumaní\n",
      "Dagua:Zipaquirá w:42968333.0 p:6.171903232457098e-274\t\t263\t\t8\t\t194\t\t\t\n",
      "Terminado Dagua\n",
      "Doradal:Zipaquirá w:46995294.0 p:7.62970480722828e-178\t\t-157\t\t97\t\t71\t\t\t\n",
      "Terminado Doradal\n",
      "Duitama:Zipaquirá w:53166708.0 p:6.448458851202658e-71\t\t-64\t\t82\t\t-248\t\t\n",
      "Terminado Duitama\n",
      "El Banco:Zipaquirá w:48369751.0 p:8.460795050698063e-150\t\t27\t\t-259\t\t9\t\t\n",
      "Terminado El Banco\n",
      "El Carmen de Bolívar:Zipaquirá w:48413387.0 p:5.9789831458234135e-149\t\t8\t\t-266\t\t\t\n",
      "Terminado El Carmen de Bolívar\n",
      "El Cerrito:Zipaquirá w:42919684.0 p:3.1346593273544084e-275\t\t9\t\t88\t\t279\t\t\t\n",
      "Terminado El Cerrito\n",
      "El Copey:Zipaquirá w:51264846.0 p:1.1335021353624252e-98\t\t\t\t\t\t7e-65\t\t\n",
      "Terminado El Copey\n",
      "Espinal:Zipaquirá w:41975022.0 p:6.892843838551525e-301\t\t248\t\t104\t\t00\t\t\n",
      "Terminado Espinal\n",
      "Florencia:Zipaquirá w:44025289.0 p:1.1093134704236599e-246\t\t\t\te-22\t\t59\t\t\n",
      "Terminado Florencia\n",
      "Florida:Zipaquirá w:63355108.0 p:0.7911330454866627\t\t\t\t\t\t403e-135\t\t5\t\t\n",
      "Terminado Florida\n",
      "Fonseca:Zipaquirá w:52477415.0 p:1.9716704782018923e-80\t\t3\t\t-90\t\t226\t\t\n",
      "Terminado Fonseca\n",
      "Fresno:Zipaquirá w:41239410.0 p:0.0\t\t2235411856e-192\t\te-291\t\t6\t\t-149\t\t\n",
      "Terminado Fresno\n",
      "Fundación:Zipaquirá w:45087901.0 p:9.224209081747899e-221\t\t83\t\t104\t\t125\t\t\n",
      "Terminado Fundación\n",
      "Fusagasugá:Zipaquirá w:45000858.0 p:8.453948078330341e-223\t\t257\t\t15\t\t145\t\t\n",
      "Terminado Fusagasugá\n",
      "Garzón:Paipa w:42612035.0 p:1.5390457002645087e-283\t\t965e-216\t\t14\t\t\t"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-a8f8a4adb934>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#wilcoxon_signedrank_matrix_all_corpus(DESTINO, method=\"zsplit\", normalize=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#print(\"\\nListo All Corpus Normalizado\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mwilcoxon_signedrank_matrix_all_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDESTINO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pratt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"maxmedian\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mwilcoxon_signedrank_matrix_all_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDESTINO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"zsplit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"maxmedian\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mwilcoxon_signedrank_matrix_all_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDESTINO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"wilcox\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"maxmedian\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-72-184ec1ccc301>\u001b[0m in \u001b[0;36mwilcoxon_signedrank_matrix_all_corpus\u001b[0;34m(origin, method, normalize, zeros)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mdiferencia_prom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiferencia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiferencia\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0mpueblo1_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpueblo2_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpueblo1_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpueblo2_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpueblo1_median\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpueblo2_median\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_statistis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"maxmedian\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mpueblo1_len\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mpueblo2_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-aab480ce7eb4>\u001b[0m in \u001b[0;36mcorpus_statistis\u001b[0;34m(origin, pueblo1, pueblo2)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mquotechar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\"'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     )\n\u001b[1;32m     10\u001b[0m     \u001b[0mpueblo1_frame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpueblo1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    560\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m _parser_defaults = {\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    813\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skip_footer not supported for iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 815\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'as_recarray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#wilcoxon_signedrank_matrix_all_corpus(DESTINO, method=\"wilcox\")\n",
    "#wilcoxon_signedrank_matrix_all_corpus(DESTINO, method=\"pratt\")\n",
    "#wilcoxon_signedrank_matrix_all_corpus(DESTINO, method=\"zsplit\")\n",
    "#print(\"\\nListo All Corpus\")\n",
    "#wilcoxon_signedrank_matrix_all_corpus(DESTINO, method=\"wilcox\", normalize=True)\n",
    "#wilcoxon_signedrank_matrix_all_corpus(DESTINO, method=\"pratt\", normalize=True)\n",
    "#wilcoxon_signedrank_matrix_all_corpus(DESTINO, method=\"zsplit\", normalize=True)\n",
    "#print(\"\\nListo All Corpus Normalizado\")\n",
    "wilcoxon_signedrank_matrix_all_corpus(DESTINO, method=\"pratt\", zeros=\"maxmedian\")\n",
    "wilcoxon_signedrank_matrix_all_corpus(DESTINO, method=\"zsplit\", zeros=\"maxmedian\")\n",
    "wilcoxon_signedrank_matrix_all_corpus(DESTINO, method=\"wilcox\", zeros=\"maxmedian\")\n",
    "print(\"\\nListo All Corpus maxmedian\")\n",
    "wilcoxon_signedrank_matrix_all_corpus(DESTINO, method=\"pratt\", zeros=\"conjmedian\")\n",
    "wilcoxon_signedrank_matrix_all_corpus(DESTINO, method=\"zsplit\", zeros=\"conjmedian\")\n",
    "wilcoxon_signedrank_matrix_all_corpus(DESTINO, method=\"wilcox\", zeros=\"conjmedian\")\n",
    "print(\"\\nListo All Corpus conjmedian\")\n",
    "wilcoxon_signedrank_matrix_all_corpus(DESTINO, method=\"pratt\", normalize=True, zeros=\"maxmedian\")\n",
    "wilcoxon_signedrank_matrix_all_corpus(DESTINO, method=\"zsplit\", normalize=True, zeros=\"maxmedian\")\n",
    "wilcoxon_signedrank_matrix_all_corpus(DESTINO, method=\"wilcox\", normalize=True, zeros=\"maxmedian\")\n",
    "print(\"\\nListo All Corpus normalizado maxmedian\")\n",
    "wilcoxon_signedrank_matrix_all_corpus(DESTINO, method=\"pratt\", normalize=True, zeros=\"conjmedian\")\n",
    "wilcoxon_signedrank_matrix_all_corpus(DESTINO, method=\"zsplit\", normalize=True, zeros=\"conjmedian\")\n",
    "wilcoxon_signedrank_matrix_all_corpus(DESTINO, method=\"wilcox\", normalize=True, zeros=\"conjmedian\")\n",
    "print(\"\\nListo All Corpus normalizado conjmedian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T23:25:12.323143Z",
     "start_time": "2018-01-28T23:25:12.262635Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def wilcoxon_signedrank_matrix_intersected_corpus_renormaliced_data(orgin, method=\"wilcox\"):\n",
    "    destination_folder=\"/src/data/procesados/wilcoxon_signed/intersected_corpus/{}/\".format(method)\n",
    "    words_data = pd.read_csv(\n",
    "        orgin, \n",
    "        encoding='utf-8',\n",
    "        index_col=0,\n",
    "        sep =\"\\t\",\n",
    "        decimal=\",\",\n",
    "        quotechar='\"'\n",
    "    )\n",
    "    \n",
    "    wilcoxon_dataframe = pd.DataFrame(columns=words_data.columns, dtype=np.int32)\n",
    "    pvalue_dataframe = pd.DataFrame(columns=words_data.columns, dtype=np.float64)\n",
    "    norm_wilcoxon_dataframe = pd.DataFrame(columns=words_data.columns, dtype=np.float64)\n",
    "    dist_dataframe = pd.DataFrame(columns=words_data.columns, dtype=np.float64)\n",
    "    for column1 in words_data:\n",
    "        # eliminar ceros\n",
    "        x=words_data[column1]\n",
    "        for column2 in words_data:\n",
    "            y=words_data[column2]\n",
    "            #Intersected corpus\n",
    "            intersection = pd.concat([x,y], axis=1)  \n",
    "            intersection = intersection[getattr(intersection,column1) != 0]\n",
    "            intersection = intersection[getattr(intersection,column2) != 0]\n",
    "            # renormalizar\n",
    "            totales = pd.DataFrame(intersection.apply(np.sum), columns=[\"#TOTALES#\"]).transpose()\n",
    "            intersection = pd.concat([totales, intersection])\n",
    "            intersection = intersection.iloc[0:]/intersection.iloc[0]\n",
    "            intersection.drop(labels=[\"#TOTALES#\"], inplace=True)\n",
    "            x1 = intersection.iloc[0:,0]\n",
    "            y1 = intersection.iloc[0:,1]\n",
    "            # calcular ceros para método wilcox:\n",
    "            if  (column1==\"Bogotá\" and column2==\"Medellín\"):\n",
    "                return(intersection.rank())\n",
    "            diferencia = pd.DataFrame(x1-y1, columns=[\"diferencia\"])\n",
    "            diferencia_prom = np.float64(abs(diferencia.sum())/len(diferencia))\n",
    "            if method == \"wilcox\":\n",
    "                ceros = len(diferencia[diferencia.diferencia == 0])\n",
    "                n = len(diferencia)-ceros\n",
    "            elif method == \"pratt\" or method == \"zsplit\":\n",
    "                n = len(x1)\n",
    "            # s = n*(n+1)/2 este no hay que buscar porque funciona con 4\n",
    "            s = n*(n+1)/4\n",
    "            wil, pvalue = wilcoxon(x1,y1,zero_method=method)\n",
    "            nwil = wil/s\n",
    "            dist_dataframe.loc[x1.name, y1.name]=diferencia_prom\n",
    "            pvalue_dataframe.loc[x1.name, y1.name]=pvalue\n",
    "            print('\\r{}:{} w:{} p:{}'.format(column1,column2,wil,pvalue), end=\"\\t\\t\")\n",
    "            if pvalue < 0.05:\n",
    "                wilcoxon_dataframe.loc[x1.name, y1.name]=wil\n",
    "                norm_wilcoxon_dataframe.loc[x1.name, y1.name]=nwil\n",
    "            else:\n",
    "                wilcoxon_dataframe.loc[x1.name, y1.name]=np.nan\n",
    "                norm_wilcoxon_dataframe.loc[x1.name, y1.name]=np.nan\n",
    "    wilcoxon_dataframe.to_csv('{}{}'.format(destination_folder,'stat.csv'),sep=\"\\t\",decimal=\",\",header=wilcoxon_dataframe.columns)\n",
    "    pvalue_dataframe.to_csv('{}{}'.format(destination_folder,'pvalue.csv'),sep=\"\\t\",decimal=\",\",header=pvalue_dataframe.columns)\n",
    "    norm_wilcoxon_dataframe.to_csv('{}{}'.format(destination_folder,'nstat.csv'),sep=\"\\t\",decimal=\",\",header=norm_wilcoxon_dataframe.columns)\n",
    "    dist_dataframe.to_csv('{}{}'.format(destination_folder,'distancia.csv'),sep=\"\\t\",decimal=\",\",header=dist_dataframe.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T05:43:15.463565Z",
     "start_time": "2018-01-29T05:43:15.459861Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bogotá:Mariquita w:11515259.0 p:1.1965597254413652e-57\t\t\t\t7e-60\t\t\t\t27\t\t\t\t\t\t1\t\t\t6\t\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/scipy/stats/morestats.py:2388: UserWarning: Warning: sample size too small for normal approximation.\n",
      "  warnings.warn(\"Warning: sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bogotá:Mariquita w:11515259.0 p:1.1965597254413652e-57\t\t\t\t7e-60\t\t\t\t27\t\t\t\t\t\t1\t\t\t6\t\t"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bogotá</th>\n",
       "      <th>Medellín</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>que</th>\n",
       "      <td>15857.0</td>\n",
       "      <td>15857.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la</th>\n",
       "      <td>15856.0</td>\n",
       "      <td>15856.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>15855.0</td>\n",
       "      <td>15855.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>el</th>\n",
       "      <td>15854.0</td>\n",
       "      <td>15854.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>15853.0</td>\n",
       "      <td>15853.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>15851.0</td>\n",
       "      <td>15851.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>15852.0</td>\n",
       "      <td>15852.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>me</th>\n",
       "      <td>15849.0</td>\n",
       "      <td>15850.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es</th>\n",
       "      <td>15850.0</td>\n",
       "      <td>15849.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mi</th>\n",
       "      <td>15846.0</td>\n",
       "      <td>15843.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lo</th>\n",
       "      <td>15843.0</td>\n",
       "      <td>15844.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>con</th>\n",
       "      <td>15848.0</td>\n",
       "      <td>15848.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>por</th>\n",
       "      <td>15847.0</td>\n",
       "      <td>15846.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>un</th>\n",
       "      <td>15845.0</td>\n",
       "      <td>15845.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>te</th>\n",
       "      <td>15839.0</td>\n",
       "      <td>15838.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>los</th>\n",
       "      <td>15844.0</td>\n",
       "      <td>15847.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>15840.0</td>\n",
       "      <td>15842.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twitter</th>\n",
       "      <td>15841.0</td>\n",
       "      <td>15841.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>una</th>\n",
       "      <td>15842.0</td>\n",
       "      <td>15839.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>si</th>\n",
       "      <td>15837.0</td>\n",
       "      <td>15837.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>del</th>\n",
       "      <td>15838.0</td>\n",
       "      <td>15840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yo</th>\n",
       "      <td>15833.0</td>\n",
       "      <td>15836.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>como</th>\n",
       "      <td>15834.0</td>\n",
       "      <td>15835.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tu</th>\n",
       "      <td>15824.0</td>\n",
       "      <td>15826.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pero</th>\n",
       "      <td>15832.0</td>\n",
       "      <td>15833.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ya</th>\n",
       "      <td>15830.0</td>\n",
       "      <td>15834.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>todo</th>\n",
       "      <td>15829.0</td>\n",
       "      <td>15827.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q</th>\n",
       "      <td>15826.0</td>\n",
       "      <td>15829.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mas</th>\n",
       "      <td>15821.0</td>\n",
       "      <td>15822.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>le</th>\n",
       "      <td>15828.0</td>\n",
       "      <td>15828.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>puyao</th>\n",
       "      <td>784.0</td>\n",
       "      <td>1167.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>piecitos</th>\n",
       "      <td>1057.0</td>\n",
       "      <td>3468.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atadura</th>\n",
       "      <td>1356.0</td>\n",
       "      <td>379.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>viajadera</th>\n",
       "      <td>2991.5</td>\n",
       "      <td>878.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>presionen</th>\n",
       "      <td>2004.5</td>\n",
       "      <td>379.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aplicarme</th>\n",
       "      <td>2184.5</td>\n",
       "      <td>379.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>akamaihd</th>\n",
       "      <td>656.0</td>\n",
       "      <td>1854.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apostarte</th>\n",
       "      <td>112.0</td>\n",
       "      <td>878.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intestinos</th>\n",
       "      <td>2184.5</td>\n",
       "      <td>2197.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cantaito</th>\n",
       "      <td>56.0</td>\n",
       "      <td>379.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inge</th>\n",
       "      <td>1830.5</td>\n",
       "      <td>1854.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>achantado</th>\n",
       "      <td>1511.5</td>\n",
       "      <td>878.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prometieran</th>\n",
       "      <td>545.0</td>\n",
       "      <td>177.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ruidosos</th>\n",
       "      <td>1202.0</td>\n",
       "      <td>615.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lunaa</th>\n",
       "      <td>112.0</td>\n",
       "      <td>878.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comenzarán</th>\n",
       "      <td>2518.5</td>\n",
       "      <td>2856.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concentraciones</th>\n",
       "      <td>656.0</td>\n",
       "      <td>1499.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moree</th>\n",
       "      <td>112.0</td>\n",
       "      <td>177.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alteración</th>\n",
       "      <td>1830.5</td>\n",
       "      <td>1499.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atora</th>\n",
       "      <td>2830.0</td>\n",
       "      <td>177.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aparicion</th>\n",
       "      <td>1670.0</td>\n",
       "      <td>878.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pisó</th>\n",
       "      <td>2677.0</td>\n",
       "      <td>2856.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gurrero</th>\n",
       "      <td>1356.0</td>\n",
       "      <td>878.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fili</th>\n",
       "      <td>112.0</td>\n",
       "      <td>379.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tomelo</th>\n",
       "      <td>1202.0</td>\n",
       "      <td>379.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cagaa</th>\n",
       "      <td>112.0</td>\n",
       "      <td>177.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>downhill</th>\n",
       "      <td>446.5</td>\n",
       "      <td>1167.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>estrias</th>\n",
       "      <td>656.0</td>\n",
       "      <td>2856.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brindada</th>\n",
       "      <td>656.0</td>\n",
       "      <td>878.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bellaa</th>\n",
       "      <td>112.0</td>\n",
       "      <td>615.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15857 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Bogotá  Medellín\n",
       "que              15857.0   15857.0\n",
       "la               15856.0   15856.0\n",
       "y                15855.0   15855.0\n",
       "el               15854.0   15854.0\n",
       "a                15853.0   15853.0\n",
       "no               15851.0   15851.0\n",
       "en               15852.0   15852.0\n",
       "me               15849.0   15850.0\n",
       "es               15850.0   15849.0\n",
       "mi               15846.0   15843.0\n",
       "lo               15843.0   15844.0\n",
       "con              15848.0   15848.0\n",
       "por              15847.0   15846.0\n",
       "un               15845.0   15845.0\n",
       "te               15839.0   15838.0\n",
       "los              15844.0   15847.0\n",
       "to               15840.0   15842.0\n",
       "twitter          15841.0   15841.0\n",
       "una              15842.0   15839.0\n",
       "si               15837.0   15837.0\n",
       "del              15838.0   15840.0\n",
       "yo               15833.0   15836.0\n",
       "como             15834.0   15835.0\n",
       "tu               15824.0   15826.0\n",
       "pero             15832.0   15833.0\n",
       "ya               15830.0   15834.0\n",
       "todo             15829.0   15827.0\n",
       "q                15826.0   15829.0\n",
       "mas              15821.0   15822.0\n",
       "le               15828.0   15828.0\n",
       "...                  ...       ...\n",
       "puyao              784.0    1167.0\n",
       "piecitos          1057.0    3468.5\n",
       "atadura           1356.0     379.5\n",
       "viajadera         2991.5     878.0\n",
       "presionen         2004.5     379.5\n",
       "aplicarme         2184.5     379.5\n",
       "akamaihd           656.0    1854.0\n",
       "apostarte          112.0     878.0\n",
       "intestinos        2184.5    2197.5\n",
       "cantaito            56.0     379.5\n",
       "inge              1830.5    1854.0\n",
       "achantado         1511.5     878.0\n",
       "prometieran        545.0     177.5\n",
       "ruidosos          1202.0     615.5\n",
       "lunaa              112.0     878.0\n",
       "comenzarán        2518.5    2856.0\n",
       "concentraciones    656.0    1499.0\n",
       "moree              112.0     177.5\n",
       "alteración        1830.5    1499.0\n",
       "atora             2830.0     177.5\n",
       "aparicion         1670.0     878.0\n",
       "pisó              2677.0    2856.0\n",
       "gurrero           1356.0     878.0\n",
       "fili               112.0     379.5\n",
       "tomelo            1202.0     379.5\n",
       "cagaa              112.0     177.5\n",
       "downhill           446.5    1167.0\n",
       "estrias            656.0    2856.0\n",
       "brindada           656.0     878.0\n",
       "bellaa             112.0     615.5\n",
       "\n",
       "[15857 rows x 2 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wilcoxon_signedrank_matrix_intersected_corpus_renormaliced_data(DESTINO, method=\"pratt\")\n",
    "wilcoxon_signedrank_matrix_intersected_corpus_renormaliced_data(DESTINO, method=\"wilcox\")\n",
    "wilcoxon_signedrank_matrix_intersected_corpus_renormaliced_data(DESTINO, method=\"zsplit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wilcoxon_signedrank_matrix_united_corpus_renormaliced_data(orgin, method=\"wilcox\", zeros=False):\n",
    "    destination_folder=\"/src/data/procesados/wilcoxon_signed/united_corpus/{}/\".format(method)\n",
    "    words_data = pd.read_csv(\n",
    "        orgin, \n",
    "        encoding='utf-8',\n",
    "        index_col=0,\n",
    "        sep =\"\\t\",\n",
    "        decimal=\",\",\n",
    "        quotechar='\"'\n",
    "    )\n",
    "    \n",
    "    wilcoxon_dataframe = pd.DataFrame(columns=words_data.columns, dtype=np.int32)\n",
    "    pvalue_dataframe = pd.DataFrame(columns=words_data.columns, dtype=np.float64)\n",
    "    norm_wilcoxon_dataframe = pd.DataFrame(columns=words_data.columns, dtype=np.float64)\n",
    "    dist_dataframe = pd.DataFrame(columns=words_data.columns, dtype=np.float64)\n",
    "    \n",
    "    if zeros:\n",
    "        destination_folder=\"{}/{}\".format(destination_folder,method)\n",
    "        \n",
    "    for column1 in words_data:\n",
    "        # eliminar ceros\n",
    "        x=pd.DataFrame(words_data[column1])\n",
    "        x=x[getattr(x,column1) != 0]\n",
    "        for column2 in words_data:\n",
    "            y=pd.DataFrame(words_data[column2])\n",
    "            y=y[getattr(y,column2) != 0]\n",
    "            #United corpus  \n",
    "            union = pd.concat([x,y], axis=1)\n",
    "            # renormalizar\n",
    "            totales = pd.DataFrame(union.apply(np.sum), columns=[\"#TOTALES#\"]).transpose()\n",
    "            union = pd.concat([totales, union])\n",
    "            union = union.iloc[0:]/union.iloc[0]\n",
    "            union.drop(labels=[\"#TOTALES#\"], inplace=True)\n",
    "            if zeros:\n",
    "                pueblo1_len, pueblo2_len, pueblo1_mean, pueblo2_mean, pueblo1_median, pueblo2_median=corpus_statistis(origin, column1, column2)\n",
    "                if zeros==\"maxmedian\":\n",
    "                    if pueblo1_len > pueblo2_len:\n",
    "                        union[column2]=union[column2].replace(0,pueblo1_median)\n",
    "                    if pueblo1_len < pueblo2_len:\n",
    "                        union[column1]=union[column1].replace(0,pueblo2_median)\n",
    "                if zeros==\"conjmedian\":\n",
    "                    union[column2]=union[column2].replace(0,pueblo1_median)\n",
    "                    union[column1]=union[column1].replace(0,pueblo2_median)\n",
    "            x1 = union.iloc[0:,0]\n",
    "            y1 = union.iloc[0:,1]\n",
    "            # calcular ceros para método wilcox:\n",
    "            diferencia = pd.DataFrame(x1-y1, columns=[\"diferencia\"])\n",
    "            diferencia_prom = np.float64(abs(diferencia.sum())/len(diferencia))\n",
    "            if method == \"wilcox\":\n",
    "                ceros = len(diferencia[diferencia.diferencia == 0])\n",
    "                n = len(diferencia)-ceros\n",
    "            elif method == \"pratt\" or method == \"zsplit\":\n",
    "                n = len(x1)\n",
    "            # s = n*(n+1)/2 este no hay que buscar porque funciona con 4\n",
    "            s = n*(n+1)/4\n",
    "            wil, pvalue = wilcoxon(x1,y1,zero_method=method)\n",
    "            nwil = wil/s\n",
    "            print('\\r{}:{} w:{} p:{}'.format(column1,column2,wil,pvalue), end=\"\\t\\t\")\n",
    "            if pvalue < 0.05:\n",
    "                wilcoxon_dataframe.loc[x1.name, y1.name]=wil\n",
    "                pvalue_dataframe.loc[x1.name, y1.name]=pvalue\n",
    "                norm_wilcoxon_dataframe.loc[x1.name, y1.name]=nwil\n",
    "            else:\n",
    "                wilcoxon_dataframe.loc[x1.name, y1.name]=np.nan\n",
    "                pvalue_dataframe.loc[x1.name, y1.name]=np.nan\n",
    "                norm_wilcoxon_dataframe.loc[x1.name, y1.name]=np.nan\n",
    "            dist_dataframe.loc[x1.name, y1.name]=diferencia_prom\n",
    "            if column1==\"Acevedo\" and column2==\"Bogotá\":\n",
    "                return(union)\n",
    "    wilcoxon_dataframe.to_csv('{}{}'.format(destination_folder,'stat.csv'),sep=\"\\t\",decimal=\",\",header=wilcoxon_dataframe.columns)\n",
    "    pvalue_dataframe.to_csv('{}{}'.format(destination_folder,'pvalue.csv'),sep=\"\\t\",decimal=\",\",header=pvalue_dataframe.columns)\n",
    "    norm_wilcoxon_dataframe.to_csv('{}{}'.format(destination_folder,'nstat.csv'),sep=\"\\t\",decimal=\",\",header=norm_wilcoxon_dataframe.columns)\n",
    "    dist_dataframe.to_csv('{}{}'.format(destination_folder,'distancia.csv'),sep=\"\\t\",decimal=\",\",header=dist_dataframe.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bogotá:Acevedo w:18606576.0 p:0.0\t\t2.0 p:0.2893647098119938\t\t\t\t3\t\t\t82\t\t6\t\t"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bogotá</th>\n",
       "      <th>Acevedo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>3.089060e-02</td>\n",
       "      <td>0.028027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aa</th>\n",
       "      <td>7.612008e-06</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abajo</th>\n",
       "      <td>5.054715e-05</td>\n",
       "      <td>0.000048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandona</th>\n",
       "      <td>2.133928e-05</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandonadas</th>\n",
       "      <td>8.980459e-07</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandonado</th>\n",
       "      <td>8.638346e-06</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandonando</th>\n",
       "      <td>9.835741e-07</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandonar</th>\n",
       "      <td>1.244435e-05</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandonas</th>\n",
       "      <td>1.710564e-06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandone</th>\n",
       "      <td>3.763240e-06</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandones</th>\n",
       "      <td>5.773152e-06</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abanico</th>\n",
       "      <td>8.552818e-07</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abastecimiento</th>\n",
       "      <td>1.582271e-06</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abastos</th>\n",
       "      <td>2.095440e-06</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abdomen</th>\n",
       "      <td>1.654970e-05</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abdominal</th>\n",
       "      <td>1.967148e-06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aberica</th>\n",
       "      <td>5.003398e-06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aberrante</th>\n",
       "      <td>2.394789e-06</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abierta</th>\n",
       "      <td>3.754687e-05</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abiertamente</th>\n",
       "      <td>2.865194e-06</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ablar</th>\n",
       "      <td>4.704050e-07</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abogado</th>\n",
       "      <td>2.843812e-05</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abona</th>\n",
       "      <td>1.838856e-06</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abonado</th>\n",
       "      <td>5.644860e-06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abonados</th>\n",
       "      <td>9.450864e-06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abono</th>\n",
       "      <td>2.317814e-05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abonos</th>\n",
       "      <td>1.120419e-05</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abordar</th>\n",
       "      <td>1.004956e-05</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abordo</th>\n",
       "      <td>4.490229e-06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aborrajado</th>\n",
       "      <td>9.408100e-07</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ídolos</th>\n",
       "      <td>1.210224e-05</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>íntimo</th>\n",
       "      <td>3.121779e-06</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ñ</th>\n",
       "      <td>5.901444e-06</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ñam</th>\n",
       "      <td>1.030615e-05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ñame</th>\n",
       "      <td>1.325687e-06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ñapa</th>\n",
       "      <td>2.608609e-06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ñato</th>\n",
       "      <td>1.282923e-07</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ñera</th>\n",
       "      <td>1.706287e-05</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ñeras</th>\n",
       "      <td>7.569244e-06</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ñerita</th>\n",
       "      <td>1.325687e-06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ñero</th>\n",
       "      <td>4.404701e-05</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ñeros</th>\n",
       "      <td>2.989210e-05</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ñiña</th>\n",
       "      <td>2.993486e-07</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ñomi</th>\n",
       "      <td>1.710564e-06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ñoña</th>\n",
       "      <td>5.901444e-06</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ñoño</th>\n",
       "      <td>8.296233e-06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ñoñomania</th>\n",
       "      <td>4.276409e-08</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ó</th>\n",
       "      <td>1.873067e-05</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>óptima</th>\n",
       "      <td>1.154630e-06</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>órganos</th>\n",
       "      <td>4.789578e-06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>última</th>\n",
       "      <td>1.319272e-04</td>\n",
       "      <td>0.000074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>últimas</th>\n",
       "      <td>2.548740e-05</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>último</th>\n",
       "      <td>1.809776e-04</td>\n",
       "      <td>0.000134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>últimos</th>\n",
       "      <td>7.526480e-05</td>\n",
       "      <td>0.000052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>única</th>\n",
       "      <td>2.253240e-04</td>\n",
       "      <td>0.000249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>únicamente</th>\n",
       "      <td>1.124696e-05</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>único</th>\n",
       "      <td>4.385030e-04</td>\n",
       "      <td>0.000546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>únicos</th>\n",
       "      <td>3.681988e-05</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>úsalo</th>\n",
       "      <td>3.421127e-07</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>útil</th>\n",
       "      <td>1.479637e-05</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15918 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Bogotá   Acevedo\n",
       "a               3.089060e-02  0.028027\n",
       "aa              7.612008e-06  0.000015\n",
       "abajo           5.054715e-05  0.000048\n",
       "abandona        2.133928e-05  0.000015\n",
       "abandonadas     8.980459e-07  0.000004\n",
       "abandonado      8.638346e-06  0.000015\n",
       "abandonando     9.835741e-07  0.000007\n",
       "abandonar       1.244435e-05  0.000007\n",
       "abandonas       1.710564e-06       NaN\n",
       "abandone        3.763240e-06  0.000007\n",
       "abandones       5.773152e-06  0.000011\n",
       "abanico         8.552818e-07       NaN\n",
       "abastecimiento  1.582271e-06  0.000007\n",
       "abastos         2.095440e-06  0.000004\n",
       "abdomen         1.654970e-05  0.000007\n",
       "abdominal       1.967148e-06       NaN\n",
       "aberica         5.003398e-06       NaN\n",
       "aberrante       2.394789e-06  0.000004\n",
       "abierta         3.754687e-05  0.000026\n",
       "abiertamente    2.865194e-06  0.000004\n",
       "ablar           4.704050e-07       NaN\n",
       "abogado         2.843812e-05  0.000011\n",
       "abona           1.838856e-06  0.000004\n",
       "abonado         5.644860e-06       NaN\n",
       "abonados        9.450864e-06       NaN\n",
       "abono           2.317814e-05       NaN\n",
       "abonos          1.120419e-05  0.000004\n",
       "abordar         1.004956e-05  0.000007\n",
       "abordo          4.490229e-06       NaN\n",
       "aborrajado      9.408100e-07       NaN\n",
       "...                      ...       ...\n",
       "ídolos          1.210224e-05  0.000011\n",
       "íntimo          3.121779e-06  0.000004\n",
       "ñ               5.901444e-06  0.000004\n",
       "ñam             1.030615e-05       NaN\n",
       "ñame            1.325687e-06       NaN\n",
       "ñapa            2.608609e-06       NaN\n",
       "ñato            1.282923e-07       NaN\n",
       "ñera            1.706287e-05  0.000004\n",
       "ñeras           7.569244e-06  0.000004\n",
       "ñerita          1.325687e-06       NaN\n",
       "ñero            4.404701e-05  0.000015\n",
       "ñeros           2.989210e-05  0.000015\n",
       "ñiña            2.993486e-07       NaN\n",
       "ñomi            1.710564e-06       NaN\n",
       "ñoña            5.901444e-06  0.000004\n",
       "ñoño            8.296233e-06       NaN\n",
       "ñoñomania       4.276409e-08       NaN\n",
       "ó               1.873067e-05  0.000019\n",
       "óptima          1.154630e-06  0.000007\n",
       "órganos         4.789578e-06       NaN\n",
       "última          1.319272e-04  0.000074\n",
       "últimas         2.548740e-05  0.000019\n",
       "último          1.809776e-04  0.000134\n",
       "últimos         7.526480e-05  0.000052\n",
       "única           2.253240e-04  0.000249\n",
       "únicamente      1.124696e-05  0.000015\n",
       "único           4.385030e-04  0.000546\n",
       "únicos          3.681988e-05  0.000026\n",
       "úsalo           3.421127e-07  0.000004\n",
       "útil            1.479637e-05  0.000007\n",
       "\n",
       "[15918 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wilcoxon_signedrank_matrix_united_corpus_renormaliced_data(DESTINO, method=\"pratt\")\n",
    "wilcoxon_signedrank_matrix_united_corpus_renormaliced_data(DESTINO, method=\"wilcox\")\n",
    "wilcoxon_signedrank_matrix_united_corpus_renormaliced_data(DESTINO, method=\"zsplit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reindex from a duplicate axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-147-1be781323cea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mdist_dataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestination_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'distancia.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdist_dataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0mwilcoxon_signedrank_smallest_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDESTINO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"wilcox\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-147-1be781323cea>\u001b[0m in \u001b[0;36mwilcoxon_signedrank_smallest_corpus\u001b[0;34m(orgin, method, normalize)\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"#TOTALES#\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"wilcox\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0mdiferencia\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"diferencia\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m                 \u001b[0mceros\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiferencia\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdiferencia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiferencia\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiferencia\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mceros\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m             mgr = self._init_mgr(data, axes=dict(index=index, columns=columns),\n\u001b[0;32m--> 222\u001b[0;31m                                  dtype=dtype, copy=copy)\n\u001b[0m\u001b[1;32m    223\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_init_mgr\u001b[0;34m(self, mgr, axes, dtype, copy)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 mgr = mgr.reindex_axis(axe,\n\u001b[1;32m    129\u001b[0m                                        \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                                        copy=False)\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;31m# make a copy if explicitly requested\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mreindex_axis\u001b[0;34m(self, new_index, axis, method, limit, fill_value, copy)\u001b[0m\n\u001b[1;32m   3556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3557\u001b[0m         return self.reindex_indexer(new_index, indexer, axis=axis,\n\u001b[0;32m-> 3558\u001b[0;31m                                     fill_value=fill_value, copy=copy)\n\u001b[0m\u001b[1;32m   3559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3560\u001b[0m     def reindex_indexer(self, new_axis, indexer, axis, fill_value=None,\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[1;32m   3584\u001b[0m         \u001b[0;31m# some axes don't allow reindexing with dups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3585\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3586\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_reindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3588\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36m_can_reindex\u001b[0;34m(self, indexer)\u001b[0m\n\u001b[1;32m   2291\u001b[0m         \u001b[0;31m# trying to reindex on an axis with duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2292\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2293\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot reindex from a duplicate axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2295\u001b[0m     def reindex(self, target, method=None, level=None, limit=None,\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reindex from a duplicate axis"
     ]
    }
   ],
   "source": [
    "def wilcoxon_signedrank_smallest_corpus(orgin, method=\"wilcox\", normalize=False):\n",
    "    destination_folder=\"/src/data/procesados/wilcoxon_signed/smallest/{}/\".format(method)\n",
    "    words_data = pd.read_csv(\n",
    "        orgin, \n",
    "        encoding='utf-8',\n",
    "        index_col=0,\n",
    "        sep =\"\\t\",\n",
    "        decimal=\",\",\n",
    "        quotechar='\"'\n",
    "    )\n",
    "    \n",
    "    wilcoxon_dataframe = pd.DataFrame(columns=words_data.columns, dtype=np.int32)\n",
    "    pvalue_dataframe = pd.DataFrame(columns=words_data.columns, dtype=np.float64)\n",
    "    norm_wilcoxon_dataframe = pd.DataFrame(columns=words_data.columns, dtype=np.float64)\n",
    "    dist_dataframe = pd.DataFrame(columns=words_data.columns, dtype=np.float64)\n",
    "              \n",
    "    for column1 in words_data:\n",
    "        x=pd.DataFrame(words_data[column1])\n",
    "        x = x[getattr(x,column1) != 0]\n",
    "        xlen = len(x)\n",
    "        for column2 in words_data:\n",
    "            y=pd.DataFrame(words_data[column2])\n",
    "            y= y[getattr(y,column1) != 0]\n",
    "            ylen = len(y)\n",
    "            if xlen > ylen:\n",
    "                words_to_drop = words_data.index - y.index\n",
    "                x = pd.DataFrame(words_data[column1]).drop(labels=words_to_drop)\n",
    "                z=pandas.concat([x,y], axis=1).fillna(0)\n",
    "            elif xlen < ylen:\n",
    "                words_to_drop = words_data.index - x.index\n",
    "                y = pd.DataFrame(words_data[column2]).drop(labels=words_to_drop)\n",
    "                z=pd.concat([x,y], axis=1).fillna(0)\n",
    "            elif xlen == ylen:\n",
    "                z=pd.concat([x,y], axis=1).fillna(0)\n",
    "            if normalize==True:\n",
    "                destination_folder=\"/src/data/procesados/wilcoxon_signed/normalized_smallest/{}/\".format(method)\n",
    "                # renormalizar\n",
    "                totales = pd.DataFrame(z.apply(np.sum), columns=[\"#TOTALES#\"]).transpose()\n",
    "                z = pd.concat([totales, z])\n",
    "                z = z.iloc[0:]/z.iloc[0]\n",
    "                z.drop(labels=[\"#TOTALES#\"], inplace=True)\n",
    "            if method == \"wilcox\":\n",
    "                diferencia = pd.DataFrame(z[column1]-z[column2], columns=[\"diferencia\"])\n",
    "                ceros = len(diferencia[diferencia.diferencia == 0])\n",
    "                n = len(diferencia)-ceros\n",
    "                return(n)\n",
    "            elif method == \"pratt\" or method == \"zsplit\":\n",
    "                n = len(words_data[column2])\n",
    "            # s = n*(n+1)/2 este no hay que buscar porque funciona con 4\n",
    "            s = n*(n+1)/4\n",
    "            wil, pvalue = wilcoxon(words_data[column1],words_data[column2],zero_method=method)\n",
    "            nwil = wil/s\n",
    "            print('\\r{}:{} w:{} p:{}'.format(column1,column2,wil,pvalue), end=\"\\t\\t\")\n",
    "            wilcoxon_dataframe.loc[column1, column2]=wil\n",
    "            pvalue_dataframe.loc[column1, column2]=pvalue\n",
    "            norm_wilcoxon_dataframe.loc[column1, column2]=nwil\n",
    "            dist_dataframe.loc[column1, column2]=diferencia_prom\n",
    " \n",
    "    wilcoxon_dataframe.to_csv('{}{}'.format(destination_folder,'stat.csv'),sep=\"\\t\",decimal=\",\",header=wilcoxon_dataframe.columns)\n",
    "    pvalue_dataframe.to_csv('{}{}'.format(destination_folder,'pvalue.csv'),sep=\"\\t\",decimal=\",\",header=pvalue_dataframe.columns)\n",
    "    norm_wilcoxon_dataframe.to_csv('{}{}'.format(destination_folder,'nstat.csv'),sep=\"\\t\",decimal=\",\",header=norm_wilcoxon_dataframe.columns)\n",
    "    dist_dataframe.to_csv('{}{}'.format(destination_folder,'distancia.csv'),sep=\"\\t\",decimal=\",\",header=dist_dataframe.columns)\n",
    "    \n",
    "wilcoxon_signedrank_smallest_corpus(DESTINO, method=\"wilcox\", normalize=False)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba de parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T06:59:38.989526Z",
     "start_time": "2018-01-29T06:59:04.810231Z"
    }
   },
   "outputs": [],
   "source": [
    "def vocabulary_size_proportion(info_file):\n",
    "    destination_folder=\"/src/data/procesados/proportions/vocabulary_proportions.csv\"\n",
    "    words_data = pd.read_csv(\n",
    "        info_file, \n",
    "        encoding='utf-8',\n",
    "        index_col=0,\n",
    "        sep =\"\\t\",\n",
    "        decimal=\",\",\n",
    "        quotechar='\"'\n",
    "    )\n",
    "    \n",
    "    proportion_dataframe = pd.DataFrame(columns=words_data.columns, dtype=np.float64)\n",
    "    for column1 in words_data:\n",
    "        # eliminar ceros\n",
    "        x=pd.DataFrame(words_data[column1], columns=[column1])\n",
    "        x=x[getattr(x,column1) != 0]\n",
    "        xlen = len(x)\n",
    "\n",
    "        for column2 in words_data:\n",
    "            y=pd.DataFrame(words_data[column2], columns=[column2])\n",
    "            y=y[getattr(y,column2) != 0]\n",
    "            ylen = len(y)\n",
    "            #Max and min lengths\n",
    "            maxim = max(xlen,ylen)\n",
    "            minim = min(xlen,ylen)\n",
    "            proportion = minim/maxim\n",
    "            proportion_dataframe.loc[column1, column2]=proportion\n",
    "    proportion_dataframe.to_csv('{}'.format(destination_folder),sep=\"\\t\",decimal=\",\",header=proportion_dataframe.columns)\n",
    "    \n",
    "vocabulary_size_proportion(\"/src/data/procesados/filtered/Filter20MILData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T06:58:54.775429Z",
     "start_time": "2018-01-29T06:58:54.767134Z"
    }
   },
   "outputs": [],
   "source": [
    "def filestatistics(file):\n",
    "    origin = pd.read_csv(\n",
    "        file, \n",
    "        encoding='utf-8',\n",
    "        index_col=0,\n",
    "        sep =\"\\t\",\n",
    "        decimal=\",\",\n",
    "        quotechar='\"'\n",
    "    )\n",
    "    origin = origin.replace(0, np.nan)\n",
    "    origin = origin.replace(1, np.nan)\n",
    "    maxim =  origin.stack().max()\n",
    "    minim = origin.stack().min()\n",
    "    prom = origin.stack().mean()\n",
    "    mediana = origin.stack().median()\n",
    "    stdandar = origin.stack().std(ddof=1)\n",
    "    return(maxim, minim, prom, mediana, stdandar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.98141837882354643,\n",
       " 0.4403663233922453,\n",
       " 0.8093902983137774,\n",
       " 0.8108697354622103,\n",
       " 0.09361734749022893)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filestatistics(\"/src/data/procesados/wilcoxon_signed/intersected_corpus/pratt/nstat.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
